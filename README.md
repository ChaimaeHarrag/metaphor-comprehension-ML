# ğŸ§  Metaphor Comprehension ML Models

This project compares three machine learning modelsâ€”Ordinal Logistic Regression (`mord`), Random Forest, and Gradient Boostingâ€”to predict metaphor comprehension based on cognitive features.

## ğŸ” Objective

To explore how age, fluid intelligence, and working memory predict metaphor understanding using interpretable and robust models.

## ğŸ’¡ Why This Matters

Figurative language processing, especially metaphors, engages complex cognitive and neural mechanisms. This project contributes to psycholinguistic research by modeling individual differences in metaphor comprehensionâ€”especially relevant to aging and cognitive variability.

## ğŸ›  Methods

- **Models**: 
  - `mord.LogisticIT` (ordinal logistic regression)
  - `RandomForestClassifier`
  - `GradientBoostingClassifier`
- **Evaluation**: Accuracy, MAE, Confusion Matrix, Cross-Validation
- **Feature Engineering**: Standardization, Label encoding
- **Visualization**: Seaborn heatmaps, matplotlib feature plots

## ğŸ“ Files

- `notebook.ipynb` â€“ full implementation in Python/Colab
- `outputs/` â€“ saved figures and classification reports
- `model_comparison.csv` â€“ summary of results

## ğŸ’¬ Example Output

| Model            | Accuracy | MAE  | CV Mean Accuracy |
|------------------|----------|------|------------------|
| LogisticIT       | 0.78     | 0.41 | 0.76             |
| Random Forest    | 0.83     | 0.35 | 0.82             |
| Gradient Boosting| 0.85     | 0.33 | 0.84             |

## ğŸ§ª Tools & Libraries

`scikit-learn`, `mord`, `pandas`, `numpy`, `seaborn`, `matplotlib`

## ğŸ‘©â€ğŸ”¬ Author

Chaimae Harrag â€“ Cognitive Scientist | Psycholinguist | Python + NLP + Machine Learning  
Project developed in the context of advanced research on language comprehension and cognitive aging.

## ğŸ”— For the Ibn Sina Neurotech Autumn School

This project demonstrates coding fluency, cognitive modeling, and readiness to work with EEG/fMRI data using Python and ML.
